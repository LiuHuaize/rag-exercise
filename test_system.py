#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å®Œæ•´RAGç³»ç»Ÿæµç¨‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
ä»EPUBæ–‡ä»¶åˆ°æœ€ç»ˆé—®ç­”çš„å®Œæ•´æµç¨‹æµ‹è¯•
"""

import sys
import os
import subprocess
sys.path.append('src')

def test_imports():
    """æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒæ¨¡å—æ˜¯å¦å¯ä»¥æ­£å¸¸å¯¼å…¥"""
    print("ğŸ” æµ‹è¯•æ¨¡å—å¯¼å…¥...")

    try:
        from epub_processor import EPUBProcessor
        print("âœ… epub_processor å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ epub_processor å¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        from vector_processor import VectorProcessor
        print("âœ… vector_processor å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ vector_processor å¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        # æµ‹è¯•analyze_xiangzi_actionsæ¨¡å—ï¼ˆåŒ…å«RAGé—®ç­”åŠŸèƒ½ï¼‰
        import analyze_xiangzi_actions
        print("âœ… analyze_xiangzi_actions å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ analyze_xiangzi_actions å¯¼å…¥å¤±è´¥: {e}")
        return False

    try:
        import process_full_novel
        print("âœ… process_full_novel å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ process_full_novel å¯¼å…¥å¤±è´¥: {e}")
        return False

    return True

def test_data_files():
    """æµ‹è¯•å¿…è¦çš„æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("\nğŸ“ æµ‹è¯•æ•°æ®æ–‡ä»¶...")

    required_files = [
        "éª†é©¼ç¥¥å­ï¼ˆä½œå®¶æ¦œç»å…¸æ–‡åº“ï¼‰.epub",
        "requirements.txt"
    ]

    optional_files = [
        "processed_luotuoxiangzi.json",
        "data/processed/luotuoxiangzi_chunks.json"
    ]

    all_required_exist = True
    for file_path in required_files:
        if os.path.exists(file_path):
            print(f"âœ… {file_path} å­˜åœ¨")
        else:
            print(f"âŒ {file_path} ä¸å­˜åœ¨")
            all_required_exist = False

    print("\nğŸ“‹ å¯é€‰æ–‡ä»¶çŠ¶æ€:")
    for file_path in optional_files:
        if os.path.exists(file_path):
            print(f"âœ… {file_path} å­˜åœ¨")
        else:
            print(f"âš ï¸ {file_path} ä¸å­˜åœ¨ï¼ˆå¯é€šè¿‡å¤„ç†æµç¨‹ç”Ÿæˆï¼‰")

    return all_required_exist

def test_json_processing():
    """æµ‹è¯•JSONæ–‡ä»¶å¤„ç†"""
    print("\nğŸ“„ æµ‹è¯•JSONæ–‡ä»¶å¤„ç†...")

    if not os.path.exists("processed_luotuoxiangzi.json"):
        print("âš ï¸ processed_luotuoxiangzi.json ä¸å­˜åœ¨")
        print("   éœ€è¦å…ˆä»EPUBæ–‡ä»¶ç”ŸæˆJSONæ–‡ä»¶")
        return False

    try:
        import json
        with open("processed_luotuoxiangzi.json", 'r', encoding='utf-8') as f:
            data = json.load(f)

        print(f"âœ… JSONæ–‡ä»¶è¯»å–æˆåŠŸ")
        print(f"   - ä¹¦å: {data['book_info']['title']}")
        print(f"   - ç« èŠ‚æ•°: {data['book_info']['total_chapters']}")
        print(f"   - æ€»å­—æ•°: {data['book_info']['total_words']}")
        return True

    except Exception as e:
        print(f"âŒ JSONæ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
        return False

def test_vector_database():
    """æµ‹è¯•å‘é‡æ•°æ®åº“æ˜¯å¦å¯ç”¨"""
    print("\nğŸ—„ï¸ æµ‹è¯•å‘é‡æ•°æ®åº“...")

    # é¦–å…ˆæ£€æŸ¥æ•°æ®åº“ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists("chroma_db"):
        print("âš ï¸ chroma_db ç›®å½•ä¸å­˜åœ¨ï¼Œéœ€è¦è¿è¡Œ python3 src/process_full_novel.py")
        return False

    try:
        from vector_processor import VectorProcessor
        processor = VectorProcessor()

        # å°è¯•è¿æ¥åˆ°ç°æœ‰é›†åˆ
        try:
            processor.create_collection(reset=False)  # ä¸é‡ç½®ï¼Œåªæ˜¯è¿æ¥
            count = processor.collection.count()
            print(f"âœ… å‘é‡æ•°æ®åº“è¿æ¥æˆåŠŸ")
            print(f"   - æ–‡æ¡£æ•°é‡: {count}")
            print(f"   - é›†åˆåç§°: {processor.collection_name}")
            print(f"   - æ¨¡å‹åç§°: {processor.model_name}")

            if count > 0:
                print("âœ… å‘é‡æ•°æ®åº“åŒ…å«æ•°æ®")
                return True
            else:
                print("âš ï¸ å‘é‡æ•°æ®åº“ä¸ºç©ºï¼Œéœ€è¦è¿è¡Œ python3 src/process_full_novel.py")
                return False
        except Exception as e:
            print(f"âš ï¸ é›†åˆä¸å­˜åœ¨æˆ–ä¸ºç©º: {e}")
            print("   éœ€è¦è¿è¡Œ python3 src/process_full_novel.py")
            return False

    except Exception as e:
        print(f"âŒ å‘é‡æ•°æ®åº“æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_search_functionality():
    """æµ‹è¯•æœç´¢åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æœç´¢åŠŸèƒ½...")

    # é¦–å…ˆæ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
    if not os.path.exists("chroma_db"):
        print("âš ï¸ å‘é‡æ•°æ®åº“ä¸å­˜åœ¨ï¼Œè·³è¿‡æœç´¢æµ‹è¯•")
        return False

    try:
        from vector_processor import VectorProcessor
        processor = VectorProcessor()

        # è¿æ¥åˆ°é›†åˆå¹¶æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        processor.create_collection(reset=False)
        count = processor.collection.count()
        if count == 0:
            print("âš ï¸ å‘é‡æ•°æ®åº“ä¸ºç©ºï¼Œè·³è¿‡æœç´¢æµ‹è¯•")
            return False

        # æµ‹è¯•æœç´¢
        query = "ç¥¥å­åšäº†ä»€ä¹ˆ"
        results = processor.search_similar(query, n_results=2)

        if results and len(results['documents'][0]) > 0:
            print(f"âœ… æœç´¢åŠŸèƒ½æ­£å¸¸")
            print(f"   æŸ¥è¯¢: {query}")
            print(f"   ç»“æœæ•°é‡: {len(results['documents'][0])}")

            # æ˜¾ç¤ºç¬¬ä¸€ä¸ªç»“æœ
            first_doc = results['documents'][0][0]
            first_metadata = results['metadatas'][0][0]
            first_distance = results['distances'][0][0]

            print(f"   ç¬¬ä¸€ä¸ªç»“æœ:")
            print(f"     ç›¸ä¼¼åº¦: {1-first_distance:.3f}")
            print(f"     ç« èŠ‚: {first_metadata.get('chapter_title', 'N/A')[:30]}...")
            print(f"     å†…å®¹: {first_doc[:50]}...")

            return True
        else:
            print("âŒ æœç´¢è¿”å›ç©ºç»“æœ")
            return False

    except Exception as e:
        print(f"âŒ æœç´¢åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    print("\nğŸŒ æµ‹è¯•APIè¿æ¥...")

    try:
        from dotenv import load_dotenv
        load_dotenv()

        api_key = os.getenv('OPENROUTER_API_KEY')
        if not api_key:
            print("âŒ æœªæ‰¾åˆ° OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
            print("   è¯·æ£€æŸ¥ .env æ–‡ä»¶")
            return False

        if api_key.startswith('sk-or-'):
            print("âœ… APIå¯†é’¥æ ¼å¼æ­£ç¡®")
            return True
        else:
            print("âš ï¸ APIå¯†é’¥æ ¼å¼å¯èƒ½ä¸æ­£ç¡®")
            return False

    except Exception as e:
        print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_process_full_novel():
    """æµ‹è¯•å®Œæ•´å°è¯´å¤„ç†æµç¨‹"""
    print("\nğŸ”„ æµ‹è¯•å®Œæ•´å°è¯´å¤„ç†æµç¨‹...")

    if not os.path.exists("processed_luotuoxiangzi.json"):
        print("âŒ ç¼ºå°‘ processed_luotuoxiangzi.json æ–‡ä»¶")
        print("   è¯·å…ˆä»EPUBæ–‡ä»¶ç”ŸæˆJSONæ–‡ä»¶")
        return False

    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¤„ç†
    chunks_file = "data/processed/luotuoxiangzi_chunks.json"
    if os.path.exists(chunks_file) and os.path.exists("chroma_db"):
        print("âœ… æ–‡æœ¬å—å’Œå‘é‡æ•°æ®åº“å·²å­˜åœ¨")
        return True

    print("âš ï¸ éœ€è¦è¿è¡Œ process_full_novel.py æ¥ç”Ÿæˆå‘é‡æ•°æ®åº“")
    return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 70)
    print("ğŸ§ª å®Œæ•´RAGç³»ç»Ÿæµç¨‹æµ‹è¯•")
    print("ğŸ“š ä»EPUBæ–‡ä»¶åˆ°é—®ç­”åˆ†æçš„ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 70)

    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("æ•°æ®æ–‡ä»¶", test_data_files),
        ("JSONå¤„ç†", test_json_processing),
        ("APIè¿æ¥", test_api_connection),
        ("å®Œæ•´æµç¨‹", test_process_full_novel),
        ("å‘é‡æ•°æ®åº“", test_vector_database),
        ("æœç´¢åŠŸèƒ½", test_search_functionality)
    ]

    passed = 0
    total = len(tests)

    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        if test_func():
            passed += 1
        else:
            print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")

    print("\n" + "=" * 70)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    print("=" * 70)

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        print("\nğŸ“ å®Œæ•´RAGæµç¨‹:")
        print("1. âœ… EPUBæ–‡ä»¶ â†’ JSONå¤„ç†")
        print("2. âœ… JSON â†’ æ–‡æœ¬åˆ†å— â†’ å‘é‡åŒ– â†’ ChromaDBå­˜å‚¨")
        print("3. âœ… å‘é‡æ£€ç´¢ â†’ RAGé—®ç­”")
        print("\nğŸš€ è¿è¡Œå®Œæ•´åˆ†æ: python3 analyze_xiangzi_actions.py")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤ä¿®å¤:")
        print("\nğŸ”§ å®Œæ•´æµç¨‹æ­¥éª¤:")
        print("1. å®‰è£…ä¾èµ–: pip install -r requirements.txt")
        print("2. ç¡®ä¿æœ‰EPUBæ–‡ä»¶: éª†é©¼ç¥¥å­ï¼ˆä½œå®¶æ¦œç»å…¸æ–‡åº“ï¼‰.epub")
        print("3. å¦‚æœæ²¡æœ‰JSONæ–‡ä»¶ï¼Œéœ€è¦å…ˆå¤„ç†EPUB")
        print("4. è¿è¡Œå‘é‡åŒ–: python3 src/process_full_novel.py")
        print("5. è¿è¡Œåˆ†æ: python3 analyze_xiangzi_actions.py")

if __name__ == "__main__":
    main()
